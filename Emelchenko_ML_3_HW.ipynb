{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder, OrdinalEncoder, MaxAbsScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 888 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.48\n",
      "R2: 0.67\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rr = Ridge()\n",
    "rr.fit(X_train, y_train)\n",
    "y_pred = rr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.41\n",
      "R2: 0.67\n",
      "Wall time: 29.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ll = Lasso()\n",
    "ll.fit(X_train, y_train)\n",
    "y_pred = ll.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Ridge()\n",
    "params = {'alpha': np.logspace(-5, 5, 11)}\n",
    "gr = GridSearchCV(estimator, params)\n",
    "gr.fit(X_train, y_train)\n",
    "y_pred = gr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Lasso()\n",
    "params = {'alpha': np.logspace(-5, 5, 11)}\n",
    "gl = GridSearchCV(estimator, params)\n",
    "gl.fit(X_train, y_train)\n",
    "y_pred = gl.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 48.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lc = LassoCV(alphas=np.logspace(-5, 5, 11))\n",
    "lc.fit(X_train, y_train)\n",
    "y_pred = lc.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rc = RidgeCV(alphas=np.logspace(-5, 5, 11))\n",
    "rc.fit(X_train, y_train)\n",
    "y_pred = rc.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# От примененной регуляризации результат практически не изменился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 5.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ls = Pipeline([('scaler', StandardScaler()), ('LinearRegression', LinearRegression())])\n",
    "ls.fit(X_train, y_train)\n",
    "y_pred = ls.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 4.96 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lm = Pipeline([('scaler', MinMaxScaler()), ('model', LinearRegression())])\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.31\n",
      "R2: 0.67\n",
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rs = Pipeline([('scaler', StandardScaler()), ('model', Ridge())])\n",
    "rs.fit(X_train, y_train)\n",
    "y_pred = rs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 23.73\n",
      "R2: 0.68\n",
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rs = Pipeline([('scaler', MinMaxScaler()), ('model', Ridge())])\n",
    "rs.fit(X_train, y_train)\n",
    "y_pred = rs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 27.58\n",
      "R2: 0.62\n",
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lss = Pipeline([('scaler', StandardScaler()), ('model', Lasso())])\n",
    "lss.fit(X_train, y_train)\n",
    "y_pred = lss.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 54.46\n",
      "R2: 0.26\n",
      "Wall time: 4.96 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lsm = Pipeline([('scaler', MinMaxScaler()), ('model', Lasso())])\n",
    "lsm.fit(X_train, y_train)\n",
    "y_pred = lsm.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В случае с Lasso масштабирование ухудшило результат. В остальном без существенных изменений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.31\n",
      "R2: 0.67\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', StandardScaler()), ('model', Ridge())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "grs = GridSearchCV(estimator, params)\n",
    "grs.fit(X_train, y_train)\n",
    "y_pred = grs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.20\n",
      "R2: 0.67\n",
      "Wall time: 232 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', MinMaxScaler()), ('model', Ridge())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "grm = GridSearchCV(estimator, params)\n",
    "grm.fit(X_train, y_train)\n",
    "y_pred = grm.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', StandardScaler()), ('model', Lasso())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "lrs = GridSearchCV(estimator, params)\n",
    "lrs.fit(X_train, y_train)\n",
    "y_pred = lrs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.29\n",
      "R2: 0.67\n",
      "Wall time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', MinMaxScaler()), ('model', Lasso())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "lrs = GridSearchCV(estimator, params)\n",
    "lrs.fit(X_train, y_train)\n",
    "y_pred = lrs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Применение масштабирования c последующим подбором параметров не улучшило модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.34\n",
      "R2: 0.82\n",
      "Wall time: 317 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "grs = GridSearchCV(estimator, params)\n",
    "grs.fit(X_train, y_train)\n",
    "y_pred = grs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.00\n",
      "R2: 0.85\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "grs = GridSearchCV(estimator, params)\n",
    "grs.fit(X_train, y_train)\n",
    "y_pred = grs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 715.1056055083385, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718.754071525845, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 812.8595198198165, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 754.4921904264884, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 780.3727297313537, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 711.2620991840956, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 714.8607698736856, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 781.2967093632633, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 752.4520829648102, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 778.9354996401507, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 665.2776407475113, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 700.3585512828959, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 709.421833500651, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 706.2428259807542, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 755.5334060792962, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.552606792184179, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.0563485907928225, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.305682071569436, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.343948369763439, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.77\n",
      "R2: 0.81\n",
      "Wall time: 669 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5172075041978133, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "grs = GridSearchCV(estimator, params)\n",
    "grs.fit(X_train, y_train)\n",
    "y_pred = grs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 798.9428664973943, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 828.9439072173088, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 922.9560961232804, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 813.4765011121474, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 859.395338912812, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 828.564722942895, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 848.4951145488396, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 934.7744049818066, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 813.1264756827342, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 847.8299364650993, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 723.7812868040992, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 817.2073862367918, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 796.2719115178512, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 659.1941761273436, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 683.617433202672, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.02402929248501, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.48358357483221, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.588332101721335, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.37576664779317, tolerance: 2.9476950246913587\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.80\n",
      "R2: 0.84\n",
      "Wall time: 604 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 964.9694349648489, tolerance: 3.509685514851485\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "params = {'model__alpha': np.logspace(-5, 5, 11)}\n",
    "grs = GridSearchCV(estimator, params)\n",
    "grs.fit(X_train, y_train)\n",
    "y_pred = grs.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 заметно увеличился, максимально до 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': Lasso(alpha=0.001), 'model__alpha': 0.001, 'polynomial__degree': 3, 'scaler': MinMaxScaler()}\n",
      "0.84497340051315\n",
      "Wall time: 17.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 474.2566972473337, tolerance: 3.509685514851485\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('polynomial', PolynomialFeatures(include_bias=False)),\n",
    "         ('model', Ridge())]\n",
    "params = {'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "          'polynomial__degree': [2, 3, 4],\n",
    "          'model': [Ridge(), Lasso()],\n",
    "          'model__alpha': np.logspace(-5, 5, 11)\n",
    "         }\n",
    "pipe = Pipeline(steps=steps)\n",
    "search_model = GridSearchCV(pipe, param_grid=params, n_jobs=2)\n",
    "\n",
    "search_model.fit(X_train, y_train)\n",
    "\n",
    "best_params = search_model.best_params_\n",
    "\n",
    "score = search_model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "48837    0\n",
       "48838    0\n",
       "48839    0\n",
       "48840    0\n",
       "48841    1\n",
       "Length: 48842, dtype: int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:,0:13]\n",
    "y = data[14]\n",
    "y = pd.Series(np.where(y == '<=50K', 0, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      int64\n",
       "1     object\n",
       "2      int64\n",
       "3     object\n",
       "4      int64\n",
       "5     object\n",
       "6     object\n",
       "7     object\n",
       "8     object\n",
       "9     object\n",
       "10     int64\n",
       "11     int64\n",
       "12     int64\n",
       "13    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorialscol = X.select_dtypes(include=\"object\").columns\n",
    "numberscol = X.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorialscol = list(X.select_dtypes('object').columns)\n",
    "C = categorialscol\n",
    "N = numberscol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39073, 14), (9769, 14), (39073,), (9769,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessor = Pipeline(steps=[(\"scaler\", MinMaxScaler()),])\n",
    "\n",
    "categorical_preprocessor = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer([(\"categorical\", categorical_preprocessor, C),\n",
    "                                  (\"numerical\", numeric_preprocessor, N)])\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 674 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  [1, 3, 5, 6, 7, 8, 9, 13]),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000, random_state=42))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_d = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7589313133381104\n",
      "0.8629459349356923\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_d)\n",
    "f1 = f1_score(y_test, y_pred_d, average=None)[0]\n",
    "print(accuracy)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessor = Pipeline(steps=[(\"scaler\", MinMaxScaler()),])\n",
    "\n",
    "categorical_preprocessor = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer([(\"categorical\", categorical_preprocessor, C),\n",
    "                                  (\"numerical\", numeric_preprocessor, N)])\n",
    "\n",
    "pipeLR = make_pipeline(preprocessor, LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
    "pipeSVC = make_pipeline(preprocessor, SVC(random_state=RANDOM_STATE))\n",
    "pipeLSVC = make_pipeline(preprocessor, LinearSVC(random_state=RANDOM_STATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.84839799 0.84829563 0.85647011 0.85145373 0.8495086 ]\n",
      "F1LR: [0.64996455 0.65129412 0.66539379 0.65882906 0.6529745 ]\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeLR\n",
    "cvs_acc = cross_val_score(pipe, X, y, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, X, y, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.8362166  0.8362166  0.84490172 0.83855446 0.84398034]\n",
      "F1LR: [0.60687961 0.61759082 0.6280383  0.61602143 0.63188406]\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeSVC\n",
    "cvs_acc = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.85065002 0.85167366 0.85728911 0.85176085 0.8531941 ]\n",
      "F1LR: [0.65137395 0.65736581 0.66458133 0.65589354 0.65986717]\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeLSVC\n",
    "cvs_acc = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy увеличился, а F1 снизился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SImodifyer = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "modifyedX = pd.DataFrame(SImodifyer.fit_transform(X), columns=X.columns).astype(X.dtypes.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.84819326 0.84901218 0.85606061 0.85063473 0.84858722]\n",
      "F1LR: [0.64648391 0.65204058 0.66571564 0.65500118 0.649443  ]\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeLR\n",
    "cvs_acc = cross_val_score(pipe, modifyedX, y, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, modifyedX, y, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.8382639  0.83539769 0.84285422 0.83865684 0.84275184]\n",
      "F1LR: [0.60949086 0.61178175 0.62257192 0.61410382 0.62664074]\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeSVC\n",
    "cvs_acc = cross_val_score(pipe, modifyedX, y, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, modifyedX, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.84911455 0.85044529 0.85421785 0.85042998 0.8499181 ]\n",
      "F1LR: [0.64396135 0.65272165 0.65703276 0.65172825 0.6492823 ]\n",
      "Wall time: 6.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeLSVC\n",
    "cvs_acc = cross_val_score(pipe, modifyedX, y, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, modifyedX, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат без особых изменений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "QMdroper = (X != '?').all(axis=1)\n",
    "dropedX = X[QMdroper]\n",
    "dropedy = y[QMdroper]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.84389165 0.84477612 0.85404688 0.84586466 0.84564352]\n",
      "F1LR: [0.65442976 0.65638767 0.67213115 0.65933529 0.65801078]\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeLR\n",
    "cvs_acc = cross_val_score(pipe, dropedX, dropedy, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, dropedX, dropedy, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.83283582 0.83150912 0.84265812 0.83270677 0.83878815]\n",
      "F1LR: [0.61663286 0.62127237 0.63855728 0.62032622 0.6367713 ]\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeSVC\n",
    "cvs_acc = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.84610282 0.84754008 0.85393631 0.84730208 0.84763379]\n",
      "F1LR: [0.65544554 0.66092943 0.6701623  0.6602706  0.6612586 ]\n",
      "Wall time: 5.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeLSVC\n",
    "cvs_acc = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В целом уменьшилось время, но результат заметно не улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeRFC = make_pipeline(preprocessor, RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "pipeGBC = make_pipeline(preprocessor, GradientBoostingClassifier(random_state=RANDOM_STATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.84997236 0.84776119 0.85338346 0.84807607 0.84564352]\n",
      "F1LR: [0.67512569 0.67017964 0.67955534 0.67238913 0.66570881]\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeRFC\n",
    "cvs_acc = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR: [0.85925926 0.8604754  0.86764706 0.8630031  0.86432994]\n",
      "F1LR: [0.67698554 0.68323293 0.69472073 0.69109948 0.68944571]\n",
      "Wall time: 39.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = pipeGBC\n",
    "cvs_acc = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='accuracy')\n",
    "cvs_f1 = cross_val_score(pipe, dropedX, dropedy, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"accuracyLR: {cvs_acc}\")\n",
    "print(f\"F1LR: {cvs_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат улучшился. Лучшая модель: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), C),\n",
    "                                       ('num', Pipeline([('scaler', MinMaxScaler())]), N)\n",
    "                                       ])\n",
    "\n",
    "encoders = [OneHotEncoder(handle_unknown='ignore'),\n",
    "            OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "            ]\n",
    "\n",
    "scalers = [StandardScaler(), MinMaxScaler()]\n",
    "\n",
    "models = [LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "          SVC(random_state=RANDOM_STATE),\n",
    "          LinearSVC(random_state=RANDOM_STATE),\n",
    "          RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "          GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "          ]\n",
    "\n",
    "search_model = Pipeline(steps=[('preprocessor', preprocessor_base), ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))])\n",
    "\n",
    "params = {\n",
    "          'preprocessor__cat__encoder': encoders,\n",
    "          'preprocessor__num': scalers,\n",
    "          'classifier': models,\n",
    "              \n",
    "          }\n",
    "\n",
    "gridsearch = GridSearchCV(search_model, param_grid=params, scoring=('accuracy', 'f1'), refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "E:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('encoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [1, 3,\n",
       "                                                                          5, 6,\n",
       "                                                                          7, 8,\n",
       "                                                                          9,\n",
       "                                                                          13]),\n",
       "                                                                        ('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          MinMaxScaler())]),\n",
       "                                                                         Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_st...\n",
       "                                        SVC(random_state=42),\n",
       "                                        LinearSVC(random_state=42),\n",
       "                                        RandomForestClassifier(random_state=42),\n",
       "                                        GradientBoostingClassifier(random_state=42)],\n",
       "                         'preprocessor__cat__encoder': [OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                        OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                       unknown_value=-1)],\n",
       "                         'preprocessor__num': [StandardScaler(),\n",
       "                                               MinMaxScaler()]},\n",
       "             refit='f1', scoring=('accuracy', 'f1'))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': GradientBoostingClassifier(random_state=42), 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore'), 'preprocessor__num': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "best_params = gridsearch.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8695874705701709\n",
      "0.6919729206963249\n"
     ]
    }
   ],
   "source": [
    "gs_accuracy = accuracy_score(y_test, gridsearch.predict(X_test))\n",
    "gs_f1 = f1_score(y_test, gridsearch.predict(X_test))\n",
    "print(gs_accuracy)\n",
    "print(gs_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
