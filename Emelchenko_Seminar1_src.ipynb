{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuSxPbblHJK1"
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# Find the roots of square equation by gradient descent\n",
    "# x ** 2 - 6 * x + 4 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Найдем корни аналитически:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.23606797749979 0.7639320225002102\n"
     ]
    }
   ],
   "source": [
    "x1 = (6 + 20**0.5)/2\n",
    "x2 = (6 - 20**0.5)/2\n",
    "print(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвести в квадрат\n",
    "# посчитать производную\n",
    "# надо начать движение от начальной точки в направлении антградиента с заданным шагом\n",
    "# x = x - lr * grad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 358 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.764, 5.236}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = 0.00001\n",
    "xs = []\n",
    "for x in range(-25,25,10):\n",
    "    f = 15\n",
    "    while round(f,10) != 0:\n",
    "        f = 4 * x**3 - 36 * x**2 + 88*x - 48\n",
    "        x = x - lr * f\n",
    "    xs.append(round(x,3))\n",
    "xss = set(xs)\n",
    "xss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJlrSHw9Fz1x"
   },
   "outputs": [],
   "source": [
    "# всегда ли сойдемся за приемлемое количество шагов?\n",
    "Количество шагов влияет на скорость работы\n",
    "# важна ли начальная точка?\n",
    "От начальной точки зависит в какой минимум будет производиться спуск\n",
    "# как найти второй корень?\n",
    "В правой части результата списка\n",
    "# как вляет ЛР?\n",
    "ЛР влияет на скорость спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2swiHK-HIOq"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# Realize forward and backward pass for linear layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_backward(da, x):\n",
    "    sig = sigmoid(x)\n",
    "\n",
    "    return da * sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(t, y):\n",
    "    return (t - y) ** 2\n",
    "\n",
    "def d_mse_loss(t, y):\n",
    "    return 2 * (y - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, n_inp, n_out, activation='sigmoid'):\n",
    "        self.w = torch.randn(n_out, n_inp) * 0.1\n",
    "        self.b = torch.randn(n_out, 1) * 0.1\n",
    "        if activation == 'sigmoid':\n",
    "            self.activ = sigmoid\n",
    "        elif activation == 'None':\n",
    "            self.activ = None\n",
    "        else:\n",
    "            raise Exception(f'Unknown activation \"{activation}\"')\n",
    "        self._clear_state()\n",
    "\n",
    "    def _clear_state(self):\n",
    "        self.lin = None\n",
    "        self.inp = None\n",
    "        self.d_w = None\n",
    "        self.d_b = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.inp = x\n",
    "        self.lin = self.w @ self.inp + self.b\n",
    "        activ = self.activ(self.lin) if self.activ is not None else self.lin\n",
    "        return activ\n",
    "    \n",
    "    def backward(self, grad): \n",
    "        if self.activ == sigmoid:\n",
    "            grad_lin = sigmoid_backward(grad, self.lin) \n",
    "        else:\n",
    "            grad_lin = grad\n",
    "       \n",
    "        m = self.inp.shape[1]\n",
    "        self.d_w = grad_lin @ self.inp.T / m    # d_in dOut\n",
    "        self.d_b = torch.sum(grad_lin, axis=1, keepdims=True) / m\n",
    "\n",
    "        grad = self.w.T @ grad_lin\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, arch: Tuple[Tuple[int, int]], activation):\n",
    "        self.layers = []\n",
    "        for i, p in enumerate(arch):\n",
    "            self.layers.append(\n",
    "                LinearLayer(p[0], p[1], activation=activation if i < len(arch)-1 else 'None')\n",
    "            )\n",
    "        self._clear_state()\n",
    "\n",
    "    def _clear_state(self):\n",
    "        for l in self.layers:\n",
    "            l._clear_state()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmLRIBk4Fz12"
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Realize 1-2 optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_5jAO8pVFz19"
   },
   "outputs": [],
   "source": [
    "class RMSProp:\n",
    "    def __init__(self, model: Model, lr= 0.0001, rho= 0.99):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.rho = rho\n",
    "        self.acc = [[torch.zeros_like(layer.w),\n",
    "                     torch.zeros_like(layer.b)] for layer in model.layers]\n",
    "\n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.model.layers):\n",
    "            self.acc[i][0] = self.rho * self.acc[i][0] + (1 - self.rho) * layer.d_w ** 2\n",
    "            self.acc[i][1] = self.rho * self.acc[i][1] + (1 - self.rho) * layer.d_b ** 2\n",
    "            adapt_lr_w = self.lr / torch.sqrt(self.acc[i][0])\n",
    "            adapt_lr_b = self.lr / torch.sqrt(self.acc[i][1])\n",
    "            layer.w -= adapt_lr_w * layer.d_w\n",
    "            layer.b -= adapt_lr_b * layer.d_b\n",
    "\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.model._clear_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, model: Model, lr= 0.0001, beta1 = 0.99, beta2 = 0.99):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.acc = [[torch.zeros_like(layer.w),\n",
    "                     torch.zeros_like(layer.b)] for layer in model.layers]\n",
    "        self.vel = [[torch.zeros_like(layer.w),\n",
    "                     torch.zeros_like(layer.b)] for layer in model.layers]\n",
    "\n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.model.layers):\n",
    "            self.vel[i][0] = self.vel[i][0] * self.beta1 + (1 - self.beta1) * layer.d_w\n",
    "            self.vel[i][1] = self.vel[i][1] * self.beta1 + (1 - self.beta1) * layer.d_b\n",
    "            self.acc[i][0] = self.beta2 * self.acc[i][0] + (1 - self.beta2) * layer.d_w ** 2\n",
    "            self.acc[i][1] = self.beta2 * self.acc[i][1] + (1 - self.beta2) * layer.d_b ** 2\n",
    "            adapt_lr_w = self.lr / torch.sqrt(self.acc[i][0])\n",
    "            adapt_lr_b = self.lr / torch.sqrt(self.acc[i][1])\n",
    "            layer.w -= adapt_lr_w * self.vel[i][0]\n",
    "            layer.b -= adapt_lr_b * self.vel[i][1]\n",
    "\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.model._clear_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.rand(2000)-0.5)*4\n",
    "y = x**2 + torch.randn(1)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bOOY8douFz1-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.9825]]) tensor([[0.9705]]) tensor([[1.0077]]) tensor([[1.0207]])\n",
      "1 tensor([[0.9828]]) tensor([[0.9704]]) tensor([[1.0101]]) tensor([[1.0249]])\n",
      "2 tensor([[0.9845]]) tensor([[0.9733]]) tensor([[1.0111]]) tensor([[1.0265]])\n",
      "3 tensor([[0.9862]]) tensor([[0.9773]]) tensor([[1.0123]]) tensor([[1.0296]])\n",
      "4 tensor([[0.9865]]) tensor([[0.9836]]) tensor([[1.0160]]) tensor([[1.0410]])\n",
      "5 tensor([[0.9812]]) tensor([[1.0049]]) tensor([[1.0296]]) tensor([[1.0900]])\n",
      "6 tensor([[0.9752]]) tensor([[1.1181]]) tensor([[1.0563]]) tensor([[1.2455]])\n",
      "7 tensor([[1.0162]]) tensor([[1.5063]]) tensor([[1.0804]]) tensor([[1.6386]])\n",
      "8 tensor([[1.1868]]) tensor([[2.3510]]) tensor([[1.1324]]) tensor([[2.4616]])\n",
      "9 tensor([[1.3407]]) tensor([[3.2219]]) tensor([[1.2060]]) tensor([[3.3582]])\n",
      "10 tensor([[1.2829]]) tensor([[3.4318]]) tensor([[1.1403]]) tensor([[3.5601]])\n",
      "11 tensor([[1.2397]]) tensor([[3.5305]]) tensor([[1.1023]]) tensor([[3.6464]])\n",
      "12 tensor([[1.2063]]) tensor([[3.6045]]) tensor([[1.0819]]) tensor([[3.6996]])\n",
      "13 tensor([[1.1768]]) tensor([[3.6644]]) tensor([[1.0696]]) tensor([[3.7343]])\n",
      "14 tensor([[1.1491]]) tensor([[3.7138]]) tensor([[1.0598]]) tensor([[3.7587]])\n",
      "15 tensor([[1.1226]]) tensor([[3.7539]]) tensor([[1.0498]]) tensor([[3.7775]])\n",
      "16 tensor([[1.0976]]) tensor([[3.7860]]) tensor([[1.0388]]) tensor([[3.7932]])\n",
      "17 tensor([[1.0742]]) tensor([[3.8116]]) tensor([[1.0268]]) tensor([[3.8070]])\n",
      "18 tensor([[1.0530]]) tensor([[3.8321]]) tensor([[1.0146]]) tensor([[3.8196]])\n",
      "19 tensor([[1.0342]]) tensor([[3.8491]]) tensor([[1.0030]]) tensor([[3.8313]])\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelrms = Model(((1, 100), (100, 1)), activation='sigmoid')\n",
    "optim_rms = RMSProp(modelrms, lr=0.001)\n",
    "for e in range(20):\n",
    "    for i, (val, t) in enumerate(zip(x, y)):\n",
    "        optim_rms.zero_grad()\n",
    "        pred = modelrms.forward(torch.tensor([[val]]))\n",
    "        loss = mse_loss(t, pred)\n",
    "        grad = d_mse_loss(t, pred)\n",
    "        modelrms.backward(grad)\n",
    "        optim_rms.step()\n",
    "\n",
    "    print(e, modelrms.forward(torch.tensor([[1.]])), modelrms.forward(torch.tensor([[2.]])), modelrms.forward(torch.tensor([[-1.]])), modelrms.forward(torch.tensor([[-2.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zROVnJAcFz1-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[1.0457]]) tensor([[1.0289]]) tensor([[1.0792]]) tensor([[1.0964]])\n",
      "1 tensor([[1.0436]]) tensor([[1.0267]]) tensor([[1.0784]]) tensor([[1.0968]])\n",
      "2 tensor([[1.0439]]) tensor([[1.0282]]) tensor([[1.0778]]) tensor([[1.0966]])\n",
      "3 tensor([[1.0444]]) tensor([[1.0308]]) tensor([[1.0790]]) tensor([[1.1006]])\n",
      "4 tensor([[1.0416]]) tensor([[1.0354]]) tensor([[1.0845]]) tensor([[1.1195]])\n",
      "5 tensor([[1.0277]]) tensor([[1.0628]]) tensor([[1.0981]]) tensor([[1.1840]])\n",
      "6 tensor([[1.0115]]) tensor([[1.2039]]) tensor([[1.1123]]) tensor([[1.3522]])\n",
      "7 tensor([[1.0795]]) tensor([[1.6437]]) tensor([[1.1363]]) tensor([[1.7378]])\n",
      "8 tensor([[1.3138]]) tensor([[2.4711]]) tensor([[1.2483]]) tensor([[2.5126]])\n",
      "9 tensor([[1.1486]]) tensor([[2.9357]]) tensor([[0.9804]]) tensor([[3.0206]])\n",
      "10 tensor([[1.1887]]) tensor([[3.2561]]) tensor([[1.0061]]) tensor([[3.4004]])\n",
      "11 tensor([[1.1845]]) tensor([[3.3979]]) tensor([[1.0158]]) tensor([[3.5636]])\n",
      "12 tensor([[1.1700]]) tensor([[3.5003]]) tensor([[1.0247]]) tensor([[3.6536]])\n",
      "13 tensor([[1.1379]]) tensor([[3.5796]]) tensor([[0.9961]]) tensor([[3.6657]])\n",
      "14 tensor([[1.1445]]) tensor([[3.6941]]) tensor([[1.0010]]) tensor([[3.6964]])\n",
      "15 tensor([[1.1149]]) tensor([[3.7504]]) tensor([[1.0066]]) tensor([[3.7358]])\n",
      "16 tensor([[1.0364]]) tensor([[3.7355]]) tensor([[0.9757]]) tensor([[3.7410]])\n",
      "17 tensor([[0.9460]]) tensor([[3.6818]]) tensor([[0.9432]]) tensor([[3.7439]])\n",
      "18 tensor([[0.9306]]) tensor([[3.7075]]) tensor([[0.9460]]) tensor([[3.7709]])\n",
      "19 tensor([[0.9420]]) tensor([[3.7598]]) tensor([[0.9599]]) tensor([[3.8070]])\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modeladam = Model(((1, 100), (100, 1)), activation='sigmoid')\n",
    "optim_adam = Adam(modeladam, lr=0.001)\n",
    "for e in range(20):\n",
    "    for i, (val, t) in enumerate(zip(x, y)):\n",
    "        optim_adam.zero_grad()\n",
    "        pred = modeladam.forward(torch.tensor([[val]]))\n",
    "        loss = mse_loss(t, pred)\n",
    "        grad = d_mse_loss(t, pred)\n",
    "        modeladam.backward(grad)\n",
    "        optim_adam.step()\n",
    "\n",
    "    print(e, modeladam.forward(torch.tensor([[1.]])), modeladam.forward(torch.tensor([[2.]])), modeladam.forward(torch.tensor([[-1.]])), modeladam.forward(torch.tensor([[-2.]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QWQyu5NFz1-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
