{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df958d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hеализовать tfidf для quora.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb099c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93238922",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./quora.txt', encoding='utf-8') as f:\n",
    "    data = list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd60bcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What TV shows or books help you read people's body language?\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daaf4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[:100]\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b85f1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>1.977534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>2.004203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>2.118613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>2.319284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>2.570598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fulfill</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freshman</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formula</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zotac</th>\n",
       "      <td>4.921973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf_weights\n",
       "what         1.977534\n",
       "the          2.004203\n",
       "is           2.118613\n",
       "how          2.319284\n",
       "in           2.570598\n",
       "...               ...\n",
       "george       4.921973\n",
       "fulfill      4.921973\n",
       "freshman     4.921973\n",
       "formula      4.921973\n",
       "zotac        4.921973\n",
       "\n",
       "[510 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names(),columns=[\"idf_weights\"])\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2da1a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.389377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ways</th>\n",
       "      <td>0.389377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overcome</th>\n",
       "      <td>0.389377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addiction</th>\n",
       "      <td>0.389377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast</th>\n",
       "      <td>0.389377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>figo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zotac</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tfidf\n",
       "food       0.389377\n",
       "ways       0.389377\n",
       "overcome   0.389377\n",
       "addiction  0.389377\n",
       "fast       0.389377\n",
       "...             ...\n",
       "finance    0.000000\n",
       "film       0.000000\n",
       "figo       0.000000\n",
       "field      0.000000\n",
       "zotac      0.000000\n",
       "\n",
       "[510 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector=tfidf_transformer.transform(word_count)\n",
    "feature_names = count.get_feature_names()\n",
    "first_document_vector=tf_idf_vector[1]\n",
    "df_tfifd= pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df_tfifd.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b633f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Для BoW, TF-IDF и датасета quora.txt - найти самые схожие объекты (косинусное расстояние)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d006e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tokens):\n",
    "    ''' This function takes list of words in a sentence as input \n",
    "    and returns a vector of size of filtered_vocab.It puts 0 if the \n",
    "    word is not present in tokens and count of token if present.'''\n",
    "    vector=[]\n",
    "    for w in filtered_vocab:\n",
    "        vector.append(tokens.count(w))\n",
    "    return vector\n",
    "def unique(sequence):\n",
    "    '''This functions returns a list in which the order remains \n",
    "    same and no item repeats.Using the set() function does not \n",
    "    preserve the original ordering,so i didnt use that instead'''\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "#create a list of stopwords.You can import stopwords from nltk too\n",
    "stopwords=[\"to\",\"is\",\"a\"]\n",
    "\n",
    "#list of special characters.You can use regular expressions too\n",
    "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c39779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'your', 'review', 'of', 'osquery', '?']\n",
      "['what', 'is', 'your', 'review', 'of', 'ipad', 'mini', '2', '?']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "data_tok = [tokenizer.tokenize(row.lower()) for row in data]\n",
    "\n",
    "pre_data_tok = data_tok[:100]\n",
    "\n",
    "pre_dict = []\n",
    "for s in pre_data_tok:\n",
    "    pre_dict.extend(s)\n",
    "vocab = unique(pre_dict)\n",
    "\n",
    "filtered_vocab = []\n",
    "for w in vocab:\n",
    "    if w not in stopwords and w not in special_char:\n",
    "        filtered_vocab.append(w)\n",
    "\n",
    "vectors = [vectorize(s) for s in pre_data_tok]\n",
    "\n",
    "data_len = len(pre_data_tok)\n",
    "cosines = {}\n",
    "for i in range(data_len):\n",
    "    for j in range(i + 1, data_len):\n",
    "        cosines[i, j] = (np.dot(vectors[i], vectors[j]) /\n",
    "                         np.linalg.norm(vectors[i]) / np.linalg.norm(vectors[j]))\n",
    "max(cosines.values())\n",
    "cos_result = max(cosines, key=cosines.get)\n",
    "for x in cos_result:\n",
    "    print(pre_data_tok[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3e1597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'your', 'review', 'of', 'osquery', '?']\n",
      "['what', 'is', 'your', 'review', 'of', 'ipad', 'mini', '2', '?']\n"
     ]
    }
   ],
   "source": [
    "vectors = tf_idf_vector.toarray()\n",
    "\n",
    "data_len = len(pre_data_tok)\n",
    "cosines = {}\n",
    "for i in range(data_len):\n",
    "    for j in range(i + 1, data_len):\n",
    "        cosines[i, j] = (np.dot(vectors[i], vectors[j]) /\n",
    "                         np.linalg.norm(vectors[i]) / np.linalg.norm(vectors[j]))\n",
    "max(cosines.values())\n",
    "cos_result = max(cosines, key=cosines.get)\n",
    "for x in cos_result:\n",
    "    print(pre_data_tok[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
